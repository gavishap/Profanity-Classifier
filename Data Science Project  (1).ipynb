{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06513ed",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b693511",
   "metadata": {},
   "source": [
    "This project is made by Open University Computer Science students Vitaly Chait and Gabriel Shapiro. We debated on what our project should be about and we landed on the idea of profanity identification within text. We both saw the need for this type of technology to be implemented within the social media universe and we were both very interested to get to work.\n",
    "\n",
    "![Profanity_intro](ipnb_images\\\\profanity_image.jpg)\n",
    "\n",
    "## The Problem / Solution\n",
    "\n",
    "There is a constant rise to the number of devices connected to the web (IOT) and the content being spread by different people across the globe. Also, the starting age of the user is constantly decreasing to our new reality, a reality where every elementary school and even kindergarten kids are already surfing in the open web alone without any parent supervising their activity. \n",
    "\n",
    "### This leads us to the idea of our final data science & machine learning project.\n",
    "The project will create a scoring system, that will give a pass \\ no pass to content loading to its interface. Underage browsers will be able to see content that is suitable for their age by only including text that matches their threshold of profanity. There are many obstacles that must be tested for in order for the model to have a good reliability rating of correct classification. The english language is very safisticated with its grammar, and the meaning of a sentence can change with one word or one symbol. We will be working with datasets of collected sentences from the internet that we will be able to register inside our testing model and classify each sentence with a profanity grade.\n",
    "\n",
    "![Profanity_intro](ipnb_images\\\\profanity_image_kds.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c02f9",
   "metadata": {},
   "source": [
    "# 1. INIT and prerequisites "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedeb572",
   "metadata": {},
   "source": [
    "[Download and install Visual Studio](https://visualstudio.microsoft.com/downloads/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb8660",
   "metadata": {},
   "source": [
    "### If you have an Nvidia GPU you are welcomed to download CUDA \n",
    "[CUDA](https://developer.nvidia.com/cuda-downloads) + [cudnn](https://developer.nvidia.com/cudnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f7813",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c68073a",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gavis\\Downloads\\Project\n",
      "\n",
      "Python version:                          3.8.8\n",
      "scrapy version:                          2.5.1\n",
      "pandas version:                          1.2.4\n",
      "PIL version:                             8.2.0\n",
      "numpy version:                           1.20.1\n",
      "joblib version:                          1.0.1\n",
      "sklearn version:                         0.24.1\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.41.0-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.14.1-py3-none-any.whl (131 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.18.1-cp38-cp38-win_amd64.whl (912 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=b4a3bfa322226277162716b200bf6b0f7c2d0d7ba6d6d8abc2b4fd1699ff4f40\n",
      "  Stored in directory: c:\\users\\gavis\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=92ca881db4e5af4296a6f0d384bc3ad24c728dfcd696c8e74a87f14604e5b919\n",
      "  Stored in directory: c:\\users\\gavis\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: rsa, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\gavis\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c363fd30ca6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip3 install tensorflow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tensorflow version: {:>26}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "try:\n",
    "    os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\n",
    "except:\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Python version: {:>30}\".format(platform.python_version()))\n",
    "\n",
    "try:\n",
    "    import scrapy\n",
    "except:\n",
    "    !pip3 install scrapy\n",
    "print(\"scrapy version: {:>30}\".format(scrapy.__version__))\n",
    "    \n",
    "\"\"\"try:\n",
    "    import cv2\n",
    "except:\n",
    "    !pip3 install opencv-python\n",
    "print(\"OpenCV version: {:>30}\".format(cv2.__version__))\"\"\"\n",
    "\n",
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip3 install pandas\n",
    "print(\"pandas version: {:>30}\".format(pandas.__version__))\n",
    "\n",
    "try:\n",
    "    import PIL\n",
    "except:\n",
    "    !pip3 install pillow\n",
    "print(\"PIL version: {:>33}\".format(PIL.__version__))\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "except:\n",
    "    !pip3 install numpy\n",
    "print(\"numpy version: {:>32}\".format(numpy.__version__))\n",
    "    \n",
    "try:\n",
    "    import joblib\n",
    "except:\n",
    "    !pip3 install joblib\n",
    "print(\"joblib version: {:>30}\".format(joblib.__version__))\n",
    "    \n",
    "try:\n",
    "    import sklearn\n",
    "except:\n",
    "    !pip3 install sklearn    \n",
    "print(\"sklearn version: {:>30}\".format(sklearn.__version__))\n",
    "\n",
    "try:\n",
    "    import tensorflow\n",
    "except:\n",
    "    !pip3 install tensorflow \n",
    "print(\"tensorflow version: {:>26}\".format(tensorflow.__version__))\n",
    "\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "except:\n",
    "    !pip3 install matplotlib\n",
    "print(\"matplotlib version: {:>26}\".format(matplotlib.__version__))   \n",
    "\n",
    "try:\n",
    "    import IPython\n",
    "except:\n",
    "    !pip3 install IPython\n",
    "print(\"IPython version: {:>30}\".format(IPython.__version__))\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "except:\n",
    "    !pip3 install spacy\n",
    "print(\"spacy version: {:>31}\".format(spacy.__version__))\n",
    "\n",
    "try:\n",
    "    import seaborn\n",
    "except:\n",
    "    !pip3 install seaborn\n",
    "print(\"seaborn version: {:>30}\".format(seaborn.__version__))\n",
    "\n",
    "try:\n",
    "    import statsmodels\n",
    "except:\n",
    "    !pip3 install statsmodels\n",
    "print(\"statsmodels version: {:>30}\".format(statsmodels.__version__))  \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42947bf8-b609-4639-a2d8-5d0e60f331e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watermark in c:\\users\\gavis\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from watermark) (7.22.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (2.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.17.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (5.0.6)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (5.0.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (52.0.0.post20210125)\n",
      "Requirement already satisfied: backcall in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from ipython->watermark) (3.0.17)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->watermark) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\gavis\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->watermark) (0.2.0)\n",
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "PIL     : 8.2.0\n",
      "platform: 1.0.8\n",
      "scrapy  : 2.5.1\n",
      "pandas  : 1.2.4\n",
      "numpy   : 1.19.5\n",
      "joblib  : 1.0.1\n",
      "sklearn : 0.24.1\n",
      "\n",
      "Watermark: 2.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip3 install watermark\n",
    "%load_ext watermark\n",
    "\n",
    "%watermark --iversions -w\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b888a",
   "metadata": {},
   "source": [
    "![Profanity_intro](ipnb_images\\\\python_libraries.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22ccb5",
   "metadata": {},
   "source": [
    "##### @GPU_ENABLED - set True or False the parameter below for activation\n",
    "![gpu_activation](ipnb_images\\\\true_false_sign.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ENABLED = True # Change to False if you don't have GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a50521",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if GPU_ENABLED:\n",
    "    physical_devices = tensorflow.config.list_physical_devices('GPU')\n",
    "    print(\"Num GPUs:\", len(physical_devices))\n",
    "    try:\n",
    "        spacy.prefer_gpu()\n",
    "    except:\n",
    "        print(\"Not able to activate gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360676d",
   "metadata": {},
   "source": [
    "Hi reader, if you wish to optimize performence more you can read the link below\n",
    "[Feel free to read more about optimizations](https://spacy.io/usage/processing-pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384bee6f",
   "metadata": {},
   "source": [
    "![Profanity_intro](ipnb_images\\\\databases.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b6ab5",
   "metadata": {},
   "source": [
    "# 2. Data and Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2fb70",
   "metadata": {},
   "source": [
    "### 2.1 We create a Scrapy crawling code to gather data from the web for us\n",
    "\n",
    "![Profanity_intro](ipnb_images\\\\web_crawling.png)\n",
    "\n",
    "##### @Crawl - Set this parameter to \"True\" or \"False\" if you wish to activate it\n",
    "![crawl_activation](ipnb_images\\\\true_false_sign.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "activate_crawl = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564f1c1",
   "metadata": {},
   "source": [
    "### Data_C scrappy code below Files - Format is (\"file_name.py\", path) - Unpack to see the code written for this project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17b954",
   "metadata": {},
   "source": [
    "####  \"items.py\" file --> scrapygoodnews\\scrapygoodnews\\items.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class ScrapygoodnewsItem(scrapy.Item):\n",
    "    story = scrapy.Field()\n",
    "    url = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbc7ee",
   "metadata": {},
   "source": [
    "#### \"goodnews_scrape.py\" file --> scrapygoodnews\\scrapygoodnews\\spiders\\goodnews_scrape.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapygoodnews.scrapygoodnews.items import ScrapygoodnewsItem\n",
    "\n",
    "class Goodnews(scrapy.Spider):\n",
    "    name = \"my_scraper\"\n",
    "    custom_settings = {\n",
    "        'FEEDS': {\n",
    "            'scrapygoodnews\\scrapygoodnews\\output\\stories.csv': {\n",
    "                'format': 'csv',\n",
    "                'overwrite': True\n",
    "            }\n",
    "        }}\n",
    "\n",
    "    allowed_domains = ['www.goodnewsnetwork.org']\n",
    "    # First Start Url\n",
    "    start_urls = [\"https://www.goodnewsnetwork.org/category/news/page/1/\"]\n",
    "    n_pages = 10**7\n",
    "\n",
    "    for i in range(2, n_pages):\n",
    "        start_urls.append(\"https://www.goodnewsnetwork.org/category/news/page/\" + str(i))\n",
    "\n",
    "    def parse(self, response):\n",
    "        for href in response.xpath(\n",
    "                '//h3[@class=\"entry-title td-module-title\"]//@href').extract():\n",
    "            yield scrapy.Request(href, callback=self.parse_dir_contents)\n",
    "\n",
    "    def parse_dir_contents(self, response):\n",
    "        item = ScrapygoodnewsItem()\n",
    "\n",
    "        # Getting Story\n",
    "        story_list = response.xpath('//div[@class=\"td-post-content\"]//p/text()').extract()\n",
    "        story_list = [x.strip() for x in story_list if len(x.strip()) > 0]\n",
    "\n",
    "        if len(story_list) > 0:\n",
    "            item['story'] = \" \".join(story_list)# Url (The link to the page)\n",
    "            item['url'] = response.xpath(\"//meta[@property='og:url']/@content\").extract()\n",
    "            yield item\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fcfd9d",
   "metadata": {},
   "source": [
    "#### settings.py --> \\scrapygoodnews\\scrapygoodnews\\settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a072d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Partial snippet\n",
    "\"\"\"\n",
    "USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'\n",
    "LOG_LEVEL = logging.WARNING\n",
    "COOKIES_ENABLED = False\n",
    "TELNETCONSOLE_ENABLED = False\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beede43f",
   "metadata": {},
   "source": [
    "#### run_spider_file.py --> \\scrapygoodnews\\scrapygoodnews\\run_spider_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee770efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapygoodnews.scrapygoodnews.spiders.goodnews_scrape import Goodnews\n",
    "import scrapygoodnews.scrapygoodnews.settings as my_settings\n",
    "from scrapy.settings import Settings\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "stop_after_crawl = True\n",
    "\n",
    "def run_spider():\n",
    "    \"\"\"run spider with Goodnews\"\"\"\n",
    "    # Import settings from project and not terminal default path\n",
    "    crawler_settings = Settings()\n",
    "    crawler_settings.setmodule(my_settings)\n",
    "\n",
    "    crawler = CrawlerProcess(crawler_settings)\n",
    "    # Avoid Twisted reactor issue - For running the same notebook\n",
    "    print(\"Spider start running\\n /╲/\\\\(╭ •̀ •́╮)/\\\\╱\\\\ \\t /╲/\\\\(╭ •̀ •́╮)/\\╱\\\\ \\t /╲/\\\\(╭ •̀ •́╮)/\\\\╱\\\\\")\n",
    "    crawler.crawl(Goodnews)\n",
    "    crawler.start(stop_after_crawl=stop_after_crawl)\n",
    "    print(\"Spider end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapygoodnews.scrapygoodnews.run_spider_file import run_spider\n",
    "\n",
    "if activate_crawl:\n",
    "    run_spider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035e225",
   "metadata": {},
   "source": [
    "![Profanity_intro](ipnb_images\\\\data_engineer.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f89c3",
   "metadata": {},
   "source": [
    "### 2.2 The Data\n",
    "\n",
    "We will begin with explaining the datasets that we are working with. These are built quite differently.\n",
    "\n",
    "\n",
    "#### 2.2.1 Data_a\n",
    "The dataset contains twitter comments with a class column that that gives 1 if there is offensive language, 0 if there is hate speech and 2 if there is neither.\n",
    "\n",
    "\n",
    "#### 2.2.2 Data_b\n",
    "The dataset is from wikipedia texts classifies whether each text is toxic speech or threatining speech or other types, and we were able to take that and say that if any of those classifications exist that we can label it as profane language.\n",
    "\n",
    "\n",
    "#### 2.2.3 Data_c\n",
    "We will also use data from sources that were not manually labeled as part of a sponsored project (Keggle/etc..), this type of data is generated from known sources with high rate of success being correct without manual verification. \n",
    "We used scrappy opensource package to crawl \"https://www.goodnewsnetwork.org/\" and extract the text from the articles that were posted there. \n",
    "\n",
    "\n",
    "#### 2.2.4 Data_d, e, f, g, h\n",
    "Random lists of bad words we found online that come in different formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b59b6a",
   "metadata": {},
   "source": [
    "####  2.2.5 Data - Source URLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636377f2",
   "metadata": {},
   "source": [
    "##### 2.2.5.1 Labled Datasets\n",
    "[Database 1 - Source](https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data)\n",
    "\n",
    "[Database 2 - Source](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/)\n",
    "\n",
    "\n",
    "##### 2.2.5.2 Scrapy\n",
    "[The good news network website](https://www.goodnewsnetwork.org/more/about-us/)\n",
    "\n",
    "\n",
    "##### 2.2.5.3 Bad words lists\n",
    "[DB4](https://github.com/web-mech/badwords/blob/master/lib/lang.json)\n",
    "[DB5](http://www.bannedwordlist.com/)\n",
    "[DB6](https://www.freewebheaders.com/bad-words-list-and-page-moderation-words-list-for-facebook/)\n",
    "[DB7](https://www.freewebheaders.com/youtube-blacklist-words-list-youtube-comment-moderation/)\n",
    "[DB8](https://www.freewebheaders.com/full-list-of-bad-words-banned-by-google/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30e945",
   "metadata": {},
   "source": [
    "![reading_data](ipnb_images\\\\reading_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff060aef",
   "metadata": {},
   "source": [
    "## 2.3 Handling the data\n",
    "\n",
    "After we gather the datasets that we want to use we have to clean the text of any superfluous characters that will not help us with detremining the sentiment of the sentence. \n",
    "The template should be some how similiar to \"yes \\ no\" of whether the text (sentences) are offensive or not.\n",
    "\n",
    "So the goal is that for each row  we shall provide a binary indexing of \"Offensive\" or not. \n",
    "To have a uniform text template we shall use filtering techniques such as splits of the parahraph to sentences, tokenizations, characters removals and more. \n",
    "In addition we shall add another column of the words counts. This can help with determing the \"weight\" of the word on the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76222d2",
   "metadata": {},
   "source": [
    "##### @Database acivation - Set this parameter to \"True\" or \"False\" if you wish to activate\n",
    "![db_activation](ipnb_images\\\\true_false_sign.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activate_db_filtering = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de29dc1",
   "metadata": {},
   "source": [
    "### 2.3.1 First we will impot the required packages and load all the data into Pandas framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48cae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import swifter\n",
    "import numpy as np\n",
    "from spacy import load \n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, TweetTokenizer, WhitespaceTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_a = pd.read_csv(r'materials\\Cornnel\\data\\data\\labeled_data.csv')\n",
    "    data_b = pd.read_csv(r'materials\\Kaggle\\train\\train.csv')\n",
    "    data_c = pd.read_csv(r'scrapygoodnews\\scrapygoodnews\\output\\stories.csv')\n",
    "    data_d = pd.read_json(r'materials\\badwords\\word_list_a.json')\n",
    "    data_e = pd.read_csv(r'materials\\badwords\\swearWords.csv')\n",
    "    data_f = pd.read_csv(r'materials\\badwords\\format_b\\facebook-bad-words-list_comma-separated-text-file_2021_01_18.txt', sep=\"\\n\")\n",
    "    data_g = pd.read_csv(r'materials\\badwords\\format_b\\youtube-blacklist-words-list_comma-separated-text-file_2021-01-19.txt', sep=\"\\n\")\n",
    "    data_h = pd.read_csv(r'materials\\badwords\\full-list-of-bad-words_csv-file_2021_01_18\\full-list-of-bad-words_csv-file_2021_01_18.csv')\n",
    "else:\n",
    "    balanced = pd.read_csv(r'output\\database\\balanced.csv', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4dd573",
   "metadata": {},
   "source": [
    "##### The format of is:\n",
    "1. Have a peak on the data\n",
    "2. Fine tune it\n",
    "3. Have another peak on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f03833",
   "metadata": {},
   "source": [
    "![filtering_data](ipnb_images\\\\filtering_data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e8893",
   "metadata": {},
   "source": [
    "#### 2.3.1.1 Data - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557365af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_a.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6c919",
   "metadata": {},
   "source": [
    "By peaking on the database structure, we see that it has more than 2 classifications classes. The first step is to transform it to binary (Offensive or not offensive?).\n",
    "Later, we see that this data was imported from a database with Tweets, it makes sense to use the NLTK TweetTokenizer to handel the data.\n",
    "Finally we use some regular expression replacments to remove unwanted string sequences from the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_a_positive = data_a[data_a[\"class\"]==2]\n",
    "    data_a_positive = pd.DataFrame(data_a_positive[\"tweet\"])\n",
    "    data_a_positive = data_a_positive.rename(columns={\"tweet\": \"Text\"})\n",
    "    data_a_positive = data_a_positive.assign(Negative=[0 for i in range(len(data_a_positive))])\n",
    "\n",
    "    data_a_negative = data_a[data_a[\"class\"]!=2]\n",
    "    data_a_negative = pd.DataFrame(data_a_negative[\"tweet\"])\n",
    "    data_a_negative = data_a_negative.rename(columns={\"tweet\": \"Text\"})\n",
    "    data_a_negative = data_a_negative.assign(Negative=[1 for i in range(len(data_a_negative))])\n",
    "\n",
    "\n",
    "    data_a_labeled = pd.concat([data_a_positive, data_a_negative], axis=0)\n",
    "\n",
    "    tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "    data_a_labeled['Text'] = data_a_labeled['Text'].swifter.apply(tknzr.tokenize)\n",
    "    data_a_labeled['Text'] = data_a_labeled['Text'].swifter.apply(\" \".join)\n",
    "\n",
    "    data_a_labeled[\"Text\"] = data_a_labeled[\"Text\"].str.replace('\\n', ' ', regex=False)\n",
    "    data_a_labeled[\"Text\"] = data_a_labeled[\"Text\"].str.replace(r'(\"|! ! ! rt :)' , '', regex=True)\n",
    "    data_a_labeled[\"Text\"] = data_a_labeled[\"Text\"].str.replace(r'(rt : )' , '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0eeed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_a_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab9786",
   "metadata": {},
   "source": [
    "#### 2.3.1.2 Data - B \n",
    "The data is slighly different but the general idea is the same. Transform to binary classes and remove unwated string sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_b.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_b_positive = data_b.loc[(data_b['toxic']==0) & (data_b['severe_toxic']==0) & (data_b['obscene']==0) & (data_b['threat']==0) \n",
    "                                & (data_b['insult']==0) & (data_b['identity_hate']==0)]\n",
    "\n",
    "    data_b_positive = pd.DataFrame(data_b_positive[\"comment_text\"])\n",
    "    data_b_positive = data_b_positive.rename(columns={\"comment_text\": \"Text\"})\n",
    "    data_b_positive = data_b_positive.assign(Negative=[0 for i in range(len(data_b_positive))])\n",
    "\n",
    "    data_b_negative = data_b.loc[(data_b['toxic']==1) | (data_b['severe_toxic']==1) | (data_b['obscene']==1) | (data_b['threat']==1) \n",
    "                                | (data_b['insult']==1) | (data_b['identity_hate']==1)]\n",
    "    data_b_negative = pd.DataFrame(data_b_negative[\"comment_text\"])\n",
    "    data_b_negative = data_b_negative.rename(columns={\"comment_text\": \"Text\"})\n",
    "    data_b_negative = data_b_negative.assign(Negative=[1 for i in range(len(data_b_negative))])\n",
    "\n",
    "\n",
    "    data_b_labeled = pd.concat([data_b_positive, data_b_negative], axis=0)\n",
    "    data_b_labeled[\"Text\"] = data_b_labeled[\"Text\"].str.replace('\\n', ' ', regex=False)\n",
    "    data_b_labeled[\"Text\"] = data_b_labeled[\"Text\"].str.replace('\"', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de200e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_b_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f32d3",
   "metadata": {},
   "source": [
    "#### 2.3.1.3 Data - C\n",
    "Our Scrapy collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_c.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c204493",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 2.3.1.3.1 Porter Stemming \n",
    "We can use porter stemming to reduce the complexity, I eventually chose not to use it\n",
    "\n",
    "![porter_stemming](ipnb_images\\\\porter_stemming.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c60934",
   "metadata": {},
   "source": [
    "##### @Porter stemming acivation - Set this parameter to \"True\" or \"False\"\n",
    "![porter_activation](ipnb_images\\\\true_false_sign.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f06302",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_filtering = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_c_story = pd.DataFrame(data_c[\"story\"])\n",
    "    splitted_data = [] \n",
    "    \n",
    "    if porter_filtering:\n",
    "        porter = PorterStemmer()\n",
    "        for text in data_c_story[\"story\"]:\n",
    "            splitted_sent = sent_tokenize(text)\n",
    "            for sent in splitted_sent:\n",
    "                token_words = word_tokenize(sent)\n",
    "                portered = [porter.stem(word) for word in token_words]\n",
    "                splitted_data.append(\" \".join(portered))\n",
    "    else:\n",
    "        for text in data_c_story[\"story\"]:\n",
    "            splitted = sent_tokenize(text)\n",
    "            for i in splitted:\n",
    "                splitted_data.append(i)\n",
    "    \n",
    "    splitted_data = pd.DataFrame(splitted_data, columns=[\"Text\"])\n",
    "    data_c_labeled = splitted_data.assign(Negative=[0 for i in range(len(splitted_data))])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_c_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2501ba",
   "metadata": {},
   "source": [
    "#### 2.3.1.4 Data - D --> Data H\n",
    "More data, this time a lists of negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e41b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_d_labeled = data_d.rename(columns={\"words\": \"Text\"})\n",
    "    data_d_labeled = data_d_labeled.assign(Negative=[1 for i in range(len(data_d_labeled))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4990380",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_d_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_e.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_e_labeled = [[i, 1] for i in data_e]\n",
    "    data_e_labeled = pd.DataFrame(data_e_labeled, columns = [\"Text\", \"Negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add57199",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_e_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_f.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_f_labeled = data_f.iloc[7]\n",
    "    data_f_labeled = [[i,1] for i in data_f_labeled[0].split(\",\")]\n",
    "    data_f_labeled = pd.DataFrame(data_f_labeled, columns = [\"Text\", \"Negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bdcf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_f_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_g.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a976b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_g_labeled = data_g.iloc[6]\n",
    "    data_g_labeled = [[i,1] for i in data_g_labeled[0].split(\",\")]\n",
    "    data_g_labeled = pd.DataFrame(data_g_labeled, columns = [\"Text\", \"Negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7eb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_g_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_h.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2757e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_h_labeled = data_h.iloc[:, 0]\n",
    "    data_h_labeled = [[i, 1] for i in data_h_labeled]\n",
    "    data_h_labeled = pd.DataFrame(data_h_labeled, columns = [\"Text\", \"Negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    display(data_h_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae973aa6",
   "metadata": {},
   "source": [
    "# 3. Cleaning the data futher for our EDA\n",
    "Concating all the data from all different sources into 1 uniformed data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7490e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_dis = pd.DataFrame([len(data_a_labeled[data_a_labeled[\"Negative\"]==1]), len(data_a_labeled[data_a_labeled[\"Negative\"]==0])]+[len(data_b_labeled[data_b_labeled[\"Negative\"]==1]), len(data_b_labeled[data_b_labeled[\"Negative\"]==0])]+[len(data_c_labeled[data_c_labeled[\"Negative\"]==1]), len(data_c_labeled[data_c_labeled[\"Negative\"]==0])]+[len(data_d_labeled[data_d_labeled[\"Negative\"]==1]), len(data_d_labeled[data_d_labeled[\"Negative\"]==0])]+[len(data_e_labeled[data_e_labeled[\"Negative\"]==1]), len(data_e_labeled[data_e_labeled[\"Negative\"]==0])]+[len(data_f_labeled[data_f_labeled[\"Negative\"]==1]), len(data_f_labeled[data_f_labeled[\"Negative\"]==0])]+[len(data_g_labeled[data_g_labeled[\"Negative\"]==1]), len(data_g_labeled[data_g_labeled[\"Negative\"]==0])]+[len(data_h_labeled[data_h_labeled[\"Negative\"]==1]), len(data_h_labeled[data_h_labeled[\"Negative\"]==0])])\n",
    "    plt_x_axis = []\n",
    "    color_axis = []\n",
    "    [[color_axis.append(\"Red\"), color_axis.append(\"Green\"), plt_x_axis.append(\"DB \"+chr(65+i)+\"-\"),plt_x_axis.append(\"DB \"+chr(65+i)+\"+\")] for i in range(int(len(data_dis[0])/2))]\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.bar(plt_x_axis, data_dis[0], width=1, log=True, color=color_axis)\n",
    "    plt.title('Distribution of database size by negative(-) and positive(+) context')\n",
    "    plt.ylabel(\"Cells count\")\n",
    "    plt.xlabel(\"Database\")\n",
    "    print()\n",
    "else:\n",
    "    color_axis = [\"Red\", \"Green\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28609500",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    data_unfinished = pd.concat([data_a_labeled,data_b_labeled,data_c_labeled, data_d_labeled, data_e_labeled, data_f_labeled, data_g_labeled, data_h_labeled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871cab9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    neg = len(data_unfinished[data_unfinished[\"Negative\"]==1])\n",
    "    pos = len(data_unfinished[data_unfinished[\"Negative\"]==0])\n",
    "else:\n",
    "    neg = len(balanced[balanced[\"Negative\"]==1])\n",
    "    pos = len(balanced[balanced[\"Negative\"]==0])\n",
    "\n",
    "ratio = min(neg, pos)/max(neg, pos)\n",
    "\n",
    "plt.bar([\"Negative\",\"Positive\"], [neg, pos], width=0.9, color=color_axis)\n",
    "plt.title('Combined distribution of combined database size by negative(-) and positive(+) context')\n",
    "plt.ylabel(\"Cells count\")\n",
    "plt.xlabel(\"Ratio:  1 to {}\".format(round(ratio,3)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b40642",
   "metadata": {},
   "source": [
    "### 3.1 There are, unsuprisingly due to our data sources, more positive sentences than offensive. \n",
    "\n",
    "We can, by design, split the data to have the same number of positive and negative rows.\n",
    "We will also shuffel the rows to have a uniformed data spread along the sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf9097",
   "metadata": {},
   "source": [
    "##### Split - set this parameter to \"True\" or \"False\" if you wish to have balanced negative and positive sentences\n",
    "![split_activation](ipnb_images\\\\true_false_sign.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf67f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable this to have 50%/50% of negative and positive\n",
    "split_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf102fb",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    if split_data:\n",
    "        if neg>pos:\n",
    "            negative_finished = data_unfinished[data_unfinished[\"Negative\"]==1].sample(frac = ratio)\n",
    "            positive_finished = data_unfinished[data_unfinished[\"Negative\"]==0]\n",
    "        else:\n",
    "            positive_finished = data_unfinished[data_unfinished[\"Negative\"]==0].sample(frac = ratio)\n",
    "            negative_finished = data_unfinished[data_unfinished[\"Negative\"]==1]\n",
    "\n",
    "        # Concat 50/50 datasets \n",
    "        balanced = pd.concat([positive_finished,negative_finished], axis=0)\n",
    "        # Shuffle the rows \n",
    "        balanced = balanced.sample(frac = 1).reset_index(drop=True)\n",
    "        data_unbalanced = data_unfinished.sample(frac = 1).reset_index(drop=True)\n",
    "    else:\n",
    "        data_unbalanced = data_unfinished.sample(frac = 1).reset_index(drop=True)\n",
    "        balanced = data_unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(balanced[balanced[\"Negative\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56dc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(balanced[balanced[\"Negative\"]==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31143e1c",
   "metadata": {},
   "source": [
    "### 3.2 Generalize our data so that the NLP model behaves as accurate as possible\n",
    "\n",
    "In NLP, models treat words like Dog and dog differently, even if they are the same. Therefore, to overcome this problem, we lowercase the words. Here, I am using the lower() function available in Python for converting text to lowercase.\n",
    "Punctuations are the marks in English like commas, hyphens, full stops, etc. These are important for English grammar but not for text analysis. Therefore, they need to be removed.\n",
    "Contractions are the shortened versions of words like don’t for do not. We need to expand these contractions for a better analysis of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db76394",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "if activate_db_filtering:\n",
    "    balanced[\"Text\"] = balanced[\"Text\"].astype(str)\n",
    "    balanced[\"Text\"] = balanced[\"Text\"].swifter.apply(lambda x:expand_contractions(x))\n",
    "    balanced['Text'] = balanced['Text'].swifter.apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "    balanced['Text'] = balanced['Text'].swifter.apply(lambda x: x.lower())\n",
    "    balanced[\"Text\"] = balanced[\"Text\"].str.replace('  ', ' ', regex=False)\n",
    "    balanced = balanced[(balanced[[\"Text\"]] != \"\").all(axis=1)]\n",
    "    display(display(balanced.tail()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c7e59",
   "metadata": {},
   "source": [
    "### 3.3 Eventually we will tokenize the data with the same common tokenizer.\n",
    "\n",
    "To give a sense of generalization to the data and make it even more uniformed we add an optional feature to transform the data once again with tokenizer.\n",
    "We chose to use NLTK regex as a our final tokenizer and not other due to its speed.\n",
    "\n",
    "![token_benchmark](ipnb_images\\\\token_benchmark.png)\n",
    "\n",
    "Alterntaive option is to use Spacy as a our final tokenizer and not NLTK. This is because while NLTK tokenizers can have a better taylor made solutions, Spacy tokenizer has a better \"Single point solution\" that generally suits all text sources.\n",
    "\n",
    "It is important to note that usually any kind of generalization can reduce the accuracy of our model. In other words, our method will not provide the best reulsts but because the field of tokenization can have a whole notebook of itself we do not want to waste major time on that. Our point here is to enable high flexability for our datasets. Anu user might choose to add or remove some of sets in the future and will not need to customize a lot of the code. \n",
    "\n",
    "Also, as a side note, for dataset \"A\" we used NLTK tweeter custom made tokenizer. For dataset \"B\" we used the sentences NLTK tokenizer that provides faster tokenization.\n",
    "\n",
    "Because of the Spacy DependencyParser, the operation takes some time. If you run it, let the computer work for a while you drink a cup of coffee a refresh ;)\n",
    "\n",
    "[Read more about Spacy here](https://spacy.io/)\n",
    "![spacy_token](ipnb_images\\\\spacy_token.png)\n",
    "![spacy_perfo](ipnb_images\\\\spacy_perfo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14100194",
   "metadata": {},
   "source": [
    "##### @Spacy_enabled - set True or False the parameter below for activation\n",
    "![spacy_enabled](ipnb_images\\\\true_false_sign.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_enabled = True\n",
    "nltk_regex = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad29e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    if spacy_enabled:\n",
    "        try:\n",
    "            sp = spacy.load('en_core_web_sm')\n",
    "        except:\n",
    "            !python -m spacy download en_core_web_sm\n",
    "\n",
    "        sp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "        \n",
    "        # Lemmatization with stopwords removal\n",
    "        balanced['sentences']=balanced['Text'].swifter.apply(lambda x: ' '.join([token.lemma_ for token in list(sp(x)) if (token.is_stop==False)]))\n",
    "        \n",
    "    else:\n",
    "        balanced['sentences']=balanced['Text']\n",
    "        \n",
    "    \n",
    "    if nltk_regex:\n",
    "        ws_tokenize = WhitespaceTokenizer()\n",
    "        balanced['sentences'] = balanced['sentences'].swifter.apply(ws_tokenize.tokenize)\n",
    "        balanced['sentences'] = balanced['sentences'].swifter.apply(\" \".join)\n",
    "        \n",
    "    balanced = balanced[(balanced[[\"sentences\"]] != \"\").all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc44a6d",
   "metadata": {},
   "source": [
    "### 3.4 Weight per word\n",
    "\n",
    "\n",
    "We can also give weight, per word, for the sentence meaning. \n",
    "\n",
    "We must surely understand by now that \"Fuck\", a 1 word curse said alone, clearly has a negative meaning.\n",
    "While other sentences, such as: \"What the fuck just happend\", has slighly less negative meaning.\n",
    "\n",
    "Lets try to give these sentences weight by the inverse of the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d22a36",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    # We will seperate by the word counts\n",
    "    pattern = re.compile(r'\\w+')\n",
    "    balanced['Number of words'] = balanced['sentences'].swifter.apply(lambda x: max(1, len(pattern.findall(x))))\n",
    "    balanced['Weight per word'] = balanced['Number of words'].swifter.apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4e354-31b9-4ac5-835e-32fcd35baa3f",
   "metadata": {},
   "source": [
    "### 3.5 Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf98b22-8f86-4d30-9204-2f6d40fdd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    l = balanced[\"sentences\"]\n",
    "    w = balanced[\"Number of words\"]\n",
    "\n",
    "    x = [(len(i[0])-i[1]+1)/i[1] for i in zip(l,w)] \n",
    "\n",
    "    balanced = balanced.assign(AverageLength=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25794486-4315-4680-87e0-8b2be4854c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63685885-e622-43f7-9115-32ec4a276afc",
   "metadata": {},
   "source": [
    "### 3.6 Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d063b-09b9-4df2-9682-0434eee6851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    prcntl = np.percentile(balanced[\"Number of words\"], 98)\n",
    "    balanced = balanced[balanced[\"Number of words\"]<=prcntl]\n",
    "\n",
    "    prcntl = np.percentile(balanced[\"AverageLength\"], 98)\n",
    "    balanced = balanced[(balanced[\"AverageLength\"]<=prcntl) & (balanced[\"AverageLength\"]>=1.5)].reset_index(drop=True) \n",
    "\n",
    "    display(balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2035",
   "metadata": {},
   "source": [
    "### 3.7 Saving the DataBase as a CSV file\n",
    "\n",
    "##### @Save_database - set True or False the parameter below for activation\n",
    "![save_database_enabled](ipnb_images\\\\true_false_sign.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_database = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if activate_db_filtering:\n",
    "    if save_database:\n",
    "        balanced.to_csv('output\\\\database\\\\balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7a1cd",
   "metadata": {},
   "source": [
    "![eda_intro](ipnb_images\\\\eda_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a622b",
   "metadata": {},
   "source": [
    "# 4. EDA\n",
    "\n",
    "## 4.1 More library imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36a9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save results\n",
    "from joblib import dump\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels\n",
    "from collections import Counter\n",
    "\n",
    "# Model evaluation and results\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# BoW\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "result = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0a461",
   "metadata": {},
   "source": [
    "## 4.2 Database information\n",
    "\n",
    "### 4.2.1 DB Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da81499",
   "metadata": {},
   "source": [
    "### 4.2.2 Distribution of number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = balanced[\"Number of words\"]\n",
    "y = balanced[\"Negative\"]\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.hist(x, bins=25)\n",
    "plt.title('Distribution of number of words per cell')\n",
    "plt.ylabel(\"counts in bin\")\n",
    "plt.xlabel(\"Number of words\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314521c-00ad-4184-987d-5673f7ce475a",
   "metadata": {},
   "source": [
    "### 4.2.3 Distribution of context vs. number of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa7f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_list = [[j, i] for j, i in sorted(zip(x, y))]\n",
    "x = [i[0] for i in sorted_list]\n",
    "y = [i[1] for i in sorted_list]\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.hist2d(x, y, bins=[40, 2], range=[[0, 41], [0,1]], cmap='viridis')\n",
    "plt.ylabel(\"Positive        |        Negative\")\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks([])\n",
    "plt.xticks(np.arange(1,41))\n",
    "plt.xlabel(\"Number of words in a sentence\")\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('DB counts in bin')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57175875-1a08-44e4-a418-1718ca995887",
   "metadata": {},
   "source": [
    "Normalizing the plot above gives us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05f003-21a4-47a7-b9c8-257d6c320eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "data = balanced\n",
    "data[\"Positive Percentage\"] = balanced['Negative'].swifter.apply(lambda x: np.abs(1-x))\n",
    "g = sns.kdeplot(data=data, x=\"Number of words\", hue=\"Positive Percentage\", multiple=\"fill\", legend=False)\n",
    "plt.ylabel(\"Positive %       |        Negative %\")\n",
    "plt.xlim(1, min(900, max(data[\"Number of words\"])))\n",
    "plt.xlabel(\"Number of words in a sentence\")\n",
    "plt.xticks(np.arange(25, min(900, max(data[\"Number of words\"])), step=25))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29ab9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "labeled_hue = [\"Negative\" if i==1 else \"Positive\" for i in y] \n",
    "plt.figure(figsize=(18, 4))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.violinplot(x=[\"\" for i in x], y=x, hue=labeled_hue, split=True,\n",
    "               scale=\"area\", linewidth=0, palette={\"Negative\": \"r\", \"Positive\": \"g\"})\n",
    "plt.ylabel(\"Number of words in a sentence\")\n",
    "plt.xlabel(\"Number of examples in our database\")\n",
    "plt.title('Distribution')\n",
    "plt.ylim(0, max(x))\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e37b3-7059-4ad9-ab6d-cb02150641f4",
   "metadata": {},
   "source": [
    "### 4.2.4 Distribution of average words legnth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7d287-4a30-48c5-ae7e-2e859566f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balanced[\"Negative\"]\n",
    "x = balanced[\"AverageLength\"] \n",
    "plt_max_range = int(np.percentile(x, 99)) \n",
    "plt_min_range = int(np.percentile(x, 1))\n",
    "xRangeArr = np.arange(plt_min_range, plt_max_range, step=0.2)\n",
    "\n",
    "xx = [i for i in x if ((i>= plt_min_range) and (i<= plt_max_range))]\n",
    "\n",
    "mu, std = stats.norm.fit(xx) \n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.hist(x, bins=len(xRangeArr), density=True, range=[plt_min_range, plt_max_range], alpha=0.5)\n",
    "plt.title('Distribution of average word length in a sentence')\n",
    "plt.ylabel(\"Density of bin\")\n",
    "plt.xlabel(\"Average word length\")\n",
    "plt.xticks(xRangeArr)\n",
    "xmin, xmax = xRangeArr[0], xRangeArr[-1]\n",
    "plt.xlim(xmin, xmax)\n",
    "xx = np.linspace(xmin, xmax, 100)\n",
    "pp = stats.norm.pdf(xx, mu, std)\n",
    "plt.plot(xx, pp, linewidth=3, color=\"red\")\n",
    "title = \"Normal distribution of values: mean {:.2f} and std {:.2f}\".format(mu, std)\n",
    "plt.title(title, color=\"red\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c519b-a983-4ca6-9102-6e74d06808a3",
   "metadata": {},
   "source": [
    "### 4.2.5 Distribution of context vs. average words legnth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e81856-22c1-4b67-ac4a-590a5ab6f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.hist2d(x, y, bins=[40, 2], range=[[xRangeArr[0], xRangeArr[-1]], [0,1]], cmap=plt.cm.jet)\n",
    "plt.ylabel(\"Positive Sentence        |        Negative Sentence\")\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks([])\n",
    "plt.xticks(xRangeArr)\n",
    "plt.xlabel(\"Average word length in a sentence\")\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('DB counts in bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c900fb07-f5c6-4d57-98db-c9d828ee4314",
   "metadata": {},
   "source": [
    "Normalizing the plot above gives us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e5171-fc99-429e-9906-26c094cf3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "sns.kdeplot(data=data, x=\"AverageLength\", hue=\"Positive Percentage\", multiple=\"fill\", legend=False)\n",
    "plt.ylabel(\"Positive %       |        Negative %\")\n",
    "plt.xlim(max(1, min(balanced[\"AverageLength\"])), min(15, max(balanced[\"AverageLength\"])))\n",
    "plt.xticks(np.arange(max(1, min(balanced[\"AverageLength\"])), min(15, max(balanced[\"AverageLength\"])), step=1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706bffe-df07-402b-ba04-ed241870dbe5",
   "metadata": {},
   "source": [
    "### 4.2.6 Early conclusions\n",
    "\n",
    "1. There are more possible positive words available than negative words(or sentences) in our database\n",
    "2. We have more \"short\" sentences (or even single word) than long\n",
    "3. Single word cells are usually negative in our case\n",
    "4. Distribution of words legnth looks like normal distribution\n",
    "5. Looks like 2-4 letters words or more common to be offensive where 6-8 letters are more common to be safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce6260-e222-4982-b5ad-a35204e330ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_data = balanced[balanced[\"Number of words\"]<=20]\n",
    "plotting_data = plotting_data.sort_values(by=['Number of words'])\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "sns.lmplot(x=\"AverageLength\", y=\"Negative\", hue=\"Number of words\", x_bins = 20, logistic=True, data=plotting_data, \n",
    "               palette=\"coolwarm\", legend=True, height=20, aspect=20/4)\n",
    "plt.legend(handles=[g], title='Color Legend', bbox_to_anchor=(1.05, 1), fontsize = 20, loc='upper left')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a1126",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.3 Word Embeddings \n",
    "\n",
    "### 4.3.1 What are Word Embeddings?\n",
    "Word Embeddings are the texts converted into numbers. There may be different numerical representations of the same text.\n",
    "Many Machine Learning algorithms and almost all Deep Learning Architectures are incapable of processing strings or plain text in their raw form. They require numbers as inputs to perform any sort of job, be it classification, regression, etc. in broad terms.\n",
    "\n",
    "#### 4.3.1.1 N Grams\n",
    "In addition, sentences can be splitted into \"N grams\", which basically means how many word tokens we take together.\n",
    "\n",
    "![n_gram_example](ipnb_images\\\\n_gram_example.png)\n",
    "\n",
    "Selecting the N grams range to (1,2), will provide us the following output:\n",
    "\n",
    "('Bi-grams are cool!') == (['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool'])\n",
    "\n",
    "\n",
    "#### 4.3.1.2 SVD\n",
    "SVD or singular value decomposition is a factorization of a matrix. It generalizes the eigendecomposition of a square normal matrix with an orthonormal eigenbasis to any m * n matrix and it is related to the polar decomposition.\n",
    "The SVD include computing the pseudoinverse, matrix approximation, and determining the rank, range, and null space of a matrix. By creating an SVD we, sometimes, can decrease the amount of features we need to train a model to anticipate are results while keeping high accuracy.\n",
    "In our case our issue is that the dimensions of the matrix change very often (new words are added very frequently and corpus might change in size).\n",
    "Also, the matrix is extremely sparse since most words do not cooccur. There are also many features so that the reduction is somehow limmited. \n",
    "Quadratic cost to train (i.e. to perform SVD). \n",
    "\n",
    "The elements of Sigma, namely σ₁, σ₂,… σₙ are the non-zero singular values of our Sparse Matrix \"X\". The higher their value the more effect "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c0446",
   "metadata": {},
   "source": [
    "### 4.3.2 Method 1 - Bag of words and TfidfVectorizerion\n",
    "\n",
    "#### 4.3.2.1 The Bag of Words (BoW) \n",
    "BoW is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).\n",
    "\n",
    "#### 4.3.2.2 TfidfVectorizerion is CountVectorizer (bag of words) with TfidfTransformer.\n",
    "This means we basically fitst count the number of occurrences for all token and later we normalize it according to the frequencies. \n",
    "\n",
    "Term Frequent (Tf - CountVectorizer) is a measure of how frequently a term, t, appears in our dataset.\n",
    "Inverse Document Frequency (idf) is a measure of how important a term is. We need the IDF value because computing just the Tf alone is not sufficient to understand the importance of words. \n",
    "\n",
    "Hence, we see that words like “is”, “this”, “and”, etc., are reduced to values closer to 0 and have little importance; while words like “smart”, “amazing”, etc. are words less frequent, thus with more importance.\n",
    "\n",
    "![Bag_of_words](ipnb_images\\\\bag_of.png)\n",
    "\n",
    "\n",
    "#### 4.3.2.4 An advantage with count vector (and Tfidf):\n",
    "Count Vector and TF-IDF are quite easy to understand and the implementation is fairly fast to deploy.\n",
    "\n",
    "#### 4.3.2.5 A clear disadvatange with count vector (and Tfidf):\n",
    "Count Vector and TF-IDF do not capture the position in semantics, co-occurrences in the document, etc.\n",
    "\n",
    "#### 4.3.2.6 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5d15f",
   "metadata": {},
   "source": [
    "##### 4.3.2.6.1 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable\n",
    "\n",
    "bow_run = True # True/False to activate/deactivate \n",
    "save = True\n",
    "svm = True\n",
    "bernoulli_bayes = True\n",
    "multinomial_bayes = True\n",
    "complement_bayes = True\n",
    "logistic = True\n",
    "random_forest = True\n",
    "neigbors = True\n",
    "tree = True\n",
    "\n",
    "neural = True\n",
    "\n",
    "# Major effect on runtime\n",
    "ngram_range = (1,1)\n",
    "\n",
    "max_iter_runtime = 10**5  # For LinearSVC\n",
    "tolerance = 10**(-2)      # For LinearSVC\n",
    "\n",
    "neighbors = 10            # K-Neighbors\n",
    "\n",
    "min_samples_split = 2    # Decision Tree\n",
    "min_samples_leaf = 1     # Decision Tree\n",
    "\n",
    "k_fold = 5               # K fold cross validation (CV)\n",
    "\n",
    "nb_epoch=3\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c43bfbc",
   "metadata": {},
   "source": [
    "##### 4.3.2.6.2 BoW words vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc3c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bow_run:\n",
    "\n",
    "    X = balanced[\"sentences\"]\n",
    "    y = balanced['Negative']\n",
    "    \n",
    "    \n",
    "    train, test = np.split(balanced, [int(.8*len(balanced))])\n",
    "    \n",
    "\n",
    "    bag_of_words = TfidfVectorizer(stop_words=\"english\", use_idf=True)\n",
    "    X = bag_of_words.fit_transform(X) \n",
    "\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,shuffle=False)\n",
    "    \n",
    "    if save:\n",
    "        dump(bag_of_words, \"saved_runs\\tfidf\\bag_of_words.joblib\")\n",
    "        dump(X_train, \"saved_runs\\tfidf\\X.joblib\")\n",
    "        \n",
    "    ## Accuracy, Precision, Recall\n",
    "\n",
    "    classes = [\"Positive\", \"Negative\"]\n",
    "    y_test_array = pd.get_dummies(y_test, drop_first=False).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ea085",
   "metadata": {},
   "source": [
    "##### 4.3.2.6.3 Plotting the words - most of our tokens are quite unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b669988",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "idf_vector = bag_of_words.idf_ \n",
    "idf_vector = idf_vector / np.max(idf_vector)\n",
    "counts, bins = np.histogram(idf_vector)\n",
    "\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(20, 4))\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts, color=\"Orange\", log=True)\n",
    "plt.title('Histogram of words uniqueness')\n",
    "plt.xlabel('Normalzed weight per word (uniqueness index)')\n",
    "plt.ylabel('Number of unique words with that weight')\n",
    "plt.grid(True)\n",
    "plt.xticks(np.arange(0, 1, step=0.05))\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f58c0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(X_train[0:1000].todense()[:,np.random.randint(0,100,500)]==0, vmin=0, vmax=1, cmap=\"YlGnBu\",cbar=False).set_title('Sample of Sparse Matrix')\n",
    "plt.text(0.5, 0.5, 'Non zero entr', horizontalalignment='center', verticalalignment='center', size=\"large\")\n",
    "print(\"White dots are non zero values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5126b9",
   "metadata": {},
   "source": [
    "Sparse matrices are those matrices that have the majority of their elements equal to zero. In other words, the sparse matrix can be defined as the matrix that has a greater number of zero elements than the non-zero elements.\n",
    "Storing only the non-zero values and their positions is a common technique in storing sparse data sets and thus avoiding handling a sparse matrix as a dense one which makes excessive use of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449381e2",
   "metadata": {},
   "source": [
    "##### 4.3.2.6.4 SVD\n",
    "The dimensions of the matrix change very often (new words are added very frequently and corpus changes in size).\n",
    "The matrix is extremely sparse since most words do not cooccur. There are also many features so that the reduction is somehow limmited. \n",
    "Quadratic cost to train (i.e. to perform SVD). The elements of Sigma, namely σ₁, σ₂,… σₙ are the non-zero singular values of our Sparse Matrix \"X\".  \n",
    "\n",
    "\n",
    "##### 4.3.2.6.4 NOTE: NOT FINISHED YET!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fae8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=10000, n_iter=100, random_state=42)\n",
    "tfidf_lsa_data = svd.fit_transform(X)\n",
    "Sigma = svd.singular_values_\n",
    "V_T = svd.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2431a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "counts, bins = np.histogram(Sigma, bins=int(len(Sigma)/10))\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts, color=\"Orange\")\n",
    "plt.xticks(np.arange(0, np.max(Sigma), step=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69380610",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(bag_of_words.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43791b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(V_T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606684b9",
   "metadata": {},
   "source": [
    "Co-Occurrence Matrix with a fixed context window\n",
    "The big idea — Similar words tend to occur together and will have a similar context for example — Apple is a fruit. Mango is a fruit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6119646",
   "metadata": {},
   "source": [
    "# 5. The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873e013",
   "metadata": {},
   "source": [
    "### 5.1 Intro\n",
    "\n",
    "All of our posible models are based on the idea that some words can have more than 1 meaning. How to decide whether a word has a negative or positive context is not an easy task. While some words are clearly offensive, some may or may not be offensive. Thus the splitting of the data have a critical effect of the learning and validation process. One way to overcome overfitting and reach the best results it is to use cross validation.\n",
    "\n",
    "\n",
    "Also, in our case we have a new, untrained model.\n",
    "We will create our CalibratedClassifierCV. With cv in the parameters as the number of folds.\n",
    "We later fit the model. Because our model is untrained, X and y have to be used for both training and calibration. \n",
    "The way to ensure the data is 'disjoint' is our cross validation: \n",
    "for any given fold, CCCV will split X and y into your training and calibration data, so they do not overlap.\n",
    "\n",
    "![k_fold](ipnb_images\\\\k_fold.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebc0ea",
   "metadata": {},
   "source": [
    "### 5.2 Naive Bayes - Bernoulli, Multinomial, Complement . In our case Multinomial.\n",
    "\n",
    "Naive Bayes classifiers are a collection of classification algorithms based on Bayes’ Theorem\n",
    "\n",
    "#### 5.2.1 Abstract equation\n",
    "![Naive_bayes](ipnb_images\\Naive_bayes.png)\n",
    "\n",
    "In plain English, this equation is used to answer the following question. “What is the probability of y (my output variable) given X?\n",
    "\n",
    "In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters.\n",
    "Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.\n",
    "\n",
    "We have added 3 examples of Naive Bayes models that might fit our needs. \n",
    "Bare in mind the Bag Of Words can be repesented as counts, binary and freq and each one of them might have different outcomes. \n",
    "\n",
    "\n",
    "#### 5.2.2 Multinomial Naive Bayes: \n",
    "Feature vectors represent the frequencies with which certain events have been generated by a multinomial distribution. This is the event model typically used for document classification which is our case.\n",
    "Our assumption is that Multinomial Naive Bayes will best fit our needs with our frequency vector\n",
    "\n",
    "#### 5.2.3 Bernoulli Naive Bayes: \n",
    "In the multivariate Bernoulli event model, features are independent booleans (binary variables) describing inputs. Like the multinomial model, this model is popular for document classification tasks, where binary term occurrence(i.e. a word occurs in a document or not) features are used rather than term frequencies(i.e. frequency of a word in the document)\n",
    "\n",
    "#### 5.2.4 Complement Naive Bayes:\n",
    "The Complement Naive Bayes classifier was designed to correct the “severe assumptions” made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets.\n",
    "Feel free to read more here: [Rennie et al. (2003)](https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bow_run:\n",
    "# Naive Bayes\n",
    "    if bernoulli_bayes:\n",
    "        model = BernoulliNB()\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"BernoulliNB\"] = score\n",
    "        print(\"Score for bernoulli_bayes classifier with fold={} = {} %\".format(k_fold, score))\n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs/bernoulli_bayes_calibrated.joblib\")\n",
    "    \n",
    "    if complement_bayes:\n",
    "        model = ComplementNB()\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"ComplementNB\"] = score\n",
    "        print(\"Score for complement_bayes classifier with fold={} = {} %\".format(k_fold, score))\n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs/complement_bayes_calibrated.joblib\")\n",
    "    \n",
    "    if multinomial_bayes:\n",
    "        model = MultinomialNB()\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"MultinomialNB\"] = score\n",
    "        print(\"Score for multinomial_bayes classifier with fold={} = {} %\".format(k_fold, score))\n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs\\tfidf\\multinomial_bayes_calibrated.joblib\")\n",
    "            \n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d56385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = calibrated.predict(X_test)\n",
    "predicted_prob = calibrated.predict_proba(X_test)\n",
    "\n",
    "res1, res2 = map(list, zip(*predicted_prob))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, res1, multi_class=\"ovr\")\n",
    "print(\"Accuracy:{:^20}\".format(round(accuracy,2)))\n",
    "print(\"Auc:{:^30}\".format(round(auc,2)))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.gcf().set_size_inches(11.5, 4)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "print(end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495c09b",
   "metadata": {},
   "source": [
    "### 5.3 K-Neighbors classifier\n",
    "\n",
    "The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems. The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other\n",
    "\n",
    "As we increase the value of K, that is the number of neihbors, our predictions become more stable due to majority voting / averaging, and thus, more likely to make more accurate predictions (up to a certain point). Eventually, we begin to witness an increasing number of errors. It is at this point we know we have pushed the value of K too far.\n",
    "\n",
    "#### 5.3.1 Clear disadvantage of KNN\n",
    "If we look mathematically, the simple intuition is to calculate the euclidean distance from point of interest ( of whose class we need to determine) to all the points in training set. Then we take class with majority points. This is called brute force method.\n",
    "For N samples in D dimensions the running time complexity turns out to be O[DN²]. If we have small number of dimensions and training set, this would run in reasonable time. But as the training set size increases, the running time grows quickly.\n",
    "Brute force performs worst when there are large dimensions and large training set.\n",
    "\n",
    "With SKLearn fitting on sparse input always uses brute force method\n",
    "\n",
    "![KNN](ipnb_images\\\\KNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6531adf",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if bow_run:\n",
    "# K-Neighbors classifier\n",
    "    if neigbors:\n",
    "                          \n",
    "        model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"KNeighborsClassifier\"] = score\n",
    "        print(\"Score for K-Neighbors classifier with neighbors={}, fold={} > {} %\".format(neighbors, k_fold, score))\n",
    "        \n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs\\tfidf\\kneighbors_calibrated.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804dfe9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "predicted = calibrated.predict(X_test)\n",
    "predicted_prob = calibrated.predict_proba(X_test)\n",
    "\n",
    "res1, res2 = map(list, zip(*predicted_prob))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, res1, multi_class=\"ovr\")\n",
    "print(\"Accuracy:{:^20}\".format(round(accuracy,2)))\n",
    "print(\"Auc:{:^30}\".format(round(auc,2)))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.gcf().set_size_inches(11.5, 4)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "print(end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca0787",
   "metadata": {},
   "source": [
    "### 5.4 Decision tree\n",
    "\n",
    "Each node splits the decision and the more nodes we have, the more accurate the decision tree will be. \n",
    "The last nodes of the decision tree, the leaf, is where the decision is being made.\n",
    "\n",
    "![tree_image](ipnb_images\\\\tree_image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929de48",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if bow_run:\n",
    "# Decision tree classifier\n",
    "    if tree:\n",
    "                          \n",
    "        model = DecisionTreeClassifier(min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"DecisionTreeClassifier\"] = score\n",
    "        print(\"Score for Decision tree classifier with min_samples_split={}, min_samples_leaf={}, fold={} > {} %\".format(min_samples_split, min_samples_leaf, k_fold, score))\n",
    "           \n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs\\tfidf\\tree_calibrated.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fcfb7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "predicted = calibrated.predict(X_test)\n",
    "predicted_prob = calibrated.predict_proba(X_test)\n",
    "\n",
    "res1, res2 = map(list, zip(*predicted_prob))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, res1, multi_class=\"ovr\")\n",
    "print(\"Accuracy:{:^20}\".format(round(accuracy,2)))\n",
    "print(\"Auc:{:^30}\".format(round(auc,2)))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.gcf().set_size_inches(11.5, 4)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "print(end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff8921",
   "metadata": {},
   "source": [
    "### 5.5 RandomForestClassifier\n",
    "Random forests are an ensemble learning technique that builds off of decision trees. Random forests involve creating multiple decision trees using bootstrapped datasets of the original data and randomly selecting a subset of variables at each step of the decision tree. The model then selects the mode of all of the predictions of each decision tree. What’s the point of this? By relying on a “majority wins” model, it reduces the risk of error from an individual tree\n",
    "\n",
    "![random-forest](ipnb_images\\random-forest.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2f72a",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if bow_run:\n",
    "# RandomForestClassifier\n",
    "    if random_forest:\n",
    "        model = RandomForestClassifier()\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"LogisticRegression\"] = score\n",
    "        print(\"Score for RandomForestClassifier classifier with fold={} > {} %\".format(k_fold, score))\n",
    "           \n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs\\tfidf\\RandomForestClassifier_calibrated.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5b0d3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "predicted = calibrated.predict(X_test)\n",
    "predicted_prob = calibrated.predict_proba(X_test)\n",
    "\n",
    "res1, res2 = map(list, zip(*predicted_prob))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, res1, multi_class=\"ovr\")\n",
    "print(\"Accuracy:{:^20}\".format(round(accuracy,2)))\n",
    "print(\"Auc:{:^30}\".format(round(auc,2)))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.gcf().set_size_inches(11.5, 4)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "print(end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f86d0",
   "metadata": {},
   "source": [
    "### 5.6 Logistic regression\n",
    "Logistic regression is similar to linear regression but is used to model the probability of a finite number of outcomes, typically two. There are a number of reasons why logistic regression is used over linear regression when modeling probabilities of outcomes.\n",
    "\n",
    "![Logistic-regression-and-linear_regression](ipnb_images\\Logistic-regression-and-linear_regression.png)\n",
    "\n",
    "#### 5.6.1 Logistic regression equation\n",
    "\n",
    "By simple transformation, the logistic regression equation can be written in terms of an odds ratio.\n",
    "\n",
    "![Logistic-regression-and-linear_regression](ipnb_images\\logistic_formula.png)\n",
    "\n",
    "\n",
    "#### 5.6.2 Clear advantage of logistic regression\n",
    "\n",
    "In essence, a logistic equation is created in such a way that the output values can only be between 0 and 1\n",
    "The logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead, or healthy/sick.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680969ae",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if bow_run:\n",
    "# LogisticRegression\n",
    "    if logistic:\n",
    "        model = LogisticRegression()\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"LogisticRegression\"] = score\n",
    "        print(\"Score for LogisticRegression classifier with fold={} > {} %\".format(k_fold, score))\n",
    "           \n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs\\tfidf\\logistic_reg_calibrated.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf855f58",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "predicted = calibrated.predict(X_test)\n",
    "predicted_prob = calibrated.predict_proba(X_test)\n",
    "\n",
    "res1, res2 = map(list, zip(*predicted_prob))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, res1, multi_class=\"ovr\")\n",
    "print(\"Accuracy:{:^20}\".format(round(accuracy,2)))\n",
    "print(\"Auc:{:^30}\".format(round(auc,2)))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.gcf().set_size_inches(11.5, 4)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "print(end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894bd78",
   "metadata": {},
   "source": [
    "### 5.7 Support Vector Machine\n",
    "\n",
    "SVM tries to finds the “best” margin (distance between the line and the support vectors) that separates the classes and this reduces the risk of error on the data.\n",
    "\n",
    "\n",
    "![Support Vector Machine](ipnb_images\\Dim_transofrmation.png)\n",
    "![SVM_Img](ipnb_images\\SVM_Img.png)\n",
    "\n",
    "\n",
    "#### 5.7.1 Advantage of SVM\n",
    "SVM works well with unstructured and semi-structured data like text and images while logistic regression works with already identified independent variables. The risk of overfitting is less in SVM, while Logistic regression is vulnerable to overfitting.\n",
    "The algorithm creates a hyperplane or line(decision boundary) which separates data into classes. It uses the kernel trick to find the best line separator (decision boundary that has same distance from the boundary point of both classes)\n",
    "\n",
    "#### 5.7.2 Risks using SVM\n",
    "\n",
    "In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform as we surely do not have linear independent matrix and SVM does not perform very well when the data set has a lot of noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c00b5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if bow_run:\n",
    "# Linear support vector machine\n",
    "    if svm:\n",
    "         \n",
    "        model = LinearSVC(dual=False, tol=tolerance, max_iter=max_iter_runtime)\n",
    "        calibrated = CalibratedClassifierCV(base_estimator=model,cv=k_fold)\n",
    "        calibrated.fit(X_train, y_train)\n",
    "        score = calibrated.score(X_test, y_test)\n",
    "        result[\"SVM\"] = score\n",
    "        print(\"Score for Linear support vector machine with fold={} = {} %\".format(k_fold, score))\n",
    "        # CalibratedClassifierCV - \n",
    "        # This class uses cross-validation to both estimate the parameters of a classifier and subsequently calibrate a classifier\n",
    "        # fits a copy of the base estimator to the training subset, and calibrates it using the testing subset      \n",
    "        \n",
    "        if save:\n",
    "            dump(calibrated, \"saved_runs\\tfidf\\linear_svc_calibrated.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0cf354",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "predicted = calibrated.predict(X_test)\n",
    "predicted_prob = calibrated.predict_proba(X_test)\n",
    "\n",
    "res1, res2 = map(list, zip(*predicted_prob))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, res1, multi_class=\"ovr\")\n",
    "print(\"Accuracy:{:^20}\".format(round(accuracy,2)))\n",
    "print(\"Auc:{:^30}\".format(round(auc,2)))\n",
    "print(\"Detail:\")\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "## Plot confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predicted)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
    "            cbar=False)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n",
    "       yticklabels=classes, title=\"Confusion matrix\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.gcf().set_size_inches(11.5, 4)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "## Plot roc\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],  predicted_prob[:,i])\n",
    "    ax[0].plot(fpr, tpr, lw=3, \n",
    "label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                              metrics.auc(fpr, tpr))\n",
    "               )\n",
    "ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], \n",
    "          xlabel='False Positive Rate', \n",
    "          ylabel=\"True Positive Rate (Recall)\", \n",
    "          title=\"Receiver operating characteristic\")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].grid(True)\n",
    "    \n",
    "## Plot precision-recall curve\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "                 y_test_array[:,i], predicted_prob[:,i])\n",
    "    ax[1].plot(recall, precision, lw=3, \n",
    "               label='{0} (area={1:0.2f})'.format(classes[i], \n",
    "                                  metrics.auc(recall, precision))\n",
    "              )\n",
    "ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', \n",
    "          ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "ax[1].grid(True)\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "print(end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4048ddd-719c-45a1-8ede-3087a978b39d",
   "metadata": {},
   "source": [
    "### 5.8 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tScore summary for bag of words\\n\")\n",
    "for key in result:\n",
    "    print(\"{:<22}: {:>22}\".format(key, result[key]))\n",
    "    \n",
    "print(\"\\n\\n\\t\\t  Max value\\n\")\n",
    "print(\"{:<22}: {:>22}\".format(max(result), result[max(result)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9375583",
   "metadata": {},
   "source": [
    "#### 5.8.1 Linear support vector machine outperforms the other models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3ce11",
   "metadata": {},
   "source": [
    "#### Early Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c00d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_a = [\"You are shit\"]\n",
    "sample_text_b = [\"Fuck\"]\n",
    "sample_text_c = [\"I love you\"]\n",
    "sample_text_d = [\"Idan is the best teach in the Open University\"]\n",
    "sample_text_e = [\"I suck the water outside of the ship\"]\n",
    "sample_text_f = [\"I drain the water outside of the ship\"]\n",
    "sample_text_g = [\"The data I am using might or might not be refined to be better\"]\n",
    "\n",
    "\n",
    "list_of_samples = [sample_text_a, sample_text_b, sample_text_c, sample_text_d, sample_text_e, sample_text_f, sample_text_g]\n",
    "\n",
    "def _get_prob(prob):\n",
    "  return prob[1]\n",
    "    \n",
    "def probability(texts):\n",
    "  return np.apply_along_axis(_get_prob, 1, calibrated.predict_proba(bag_of_words.transform(texts)))  \n",
    "\n",
    "\n",
    "# Print the result per sample\n",
    "for sample in list_of_samples:\n",
    "    print(np.abs(1-calibrated.predict(bag_of_words.transform(sample))), end=\"\")\n",
    "    prob = probability(sample)\n",
    "    if prob[0] >= 0.5:\n",
    "        print(\"Negative {}%: {}\".format(int(np.round(prob[0], 2)*100), sample))\n",
    "    else:\n",
    "        print(\"Positive {}%: {}\".format(int(np.round(1-prob[0], 2)*100), sample))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4386ef",
   "metadata": {},
   "source": [
    "#### It can be seen that \"I suck the water outside of the ship\" failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30445a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "import transformers\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eeb287",
   "metadata": {},
   "source": [
    "### Need to complete BERT model and ELMO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "A lot of work has to be done here!!!!@@@\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "\n",
    "def elmo_vectors(x):\n",
    "    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))\n",
    "\n",
    "\n",
    "list_train = [X_train[i:i+100] for i in range(0,X_train.shape[0],100)]\n",
    "list_test = [X_test[i:i+100] for i in range(0,X_test.shape[0],100)]\n",
    "\n",
    "elmo_train = [elmo_vectors(x) for x in list_train]\n",
    "elmo_test = [elmo_vectors(x) for x in list_test]\n",
    "\n",
    "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
    "elmo_test_new = np.concatenate(elmo_test, axis = 0)\n",
    "\n",
    "# save \n",
    "dump(elmo_train_new, \"saved_runs/elmo_train_new_calibrated.joblib\")\n",
    "dump(elmo_test_new, \"saved_runs/elmo_test_new_calibrated.joblib\")\n",
    "\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, y_train, test_size=0.2, shuffle=False)\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(xtrain, ytrain)\n",
    "\n",
    "preds_valid = lreg.predict(xvalid)\n",
    "print(metrics.f1_score(yvalid, preds_valid))\n",
    "\n",
    "preds_test = lreg.predict(elmo_test_new)\n",
    "print(metrics.f1_score(y_test, preds_test))\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da67d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c860fd59",
   "metadata": {},
   "source": [
    "### TensorFlow(Keras) Multilayer Perceptron forward network model with fully connected layers\n",
    "\n",
    "![neural_layers](ipnb_images\\neural_layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc75c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Not finished - RAM issues \n",
    "if bow_run:\n",
    "# neural network\n",
    "    if neural:\n",
    "        X_train = train[\"sentences\"]\n",
    "        y_train = train['Negative']\n",
    "        X_test = test[\"sentences\"]\n",
    "        y_test = test['Negative']\n",
    "        \n",
    "        \n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(balanced[\"sentences\"])\n",
    "        \n",
    "        #Xtrain = tokenizer.texts_to_matrix(X_train, mode='binary') #  recc to set mode=\"binary\"{yes/no} or \"freq\"{tfidf}\n",
    "        #Xtest = tokenizer.texts_to_matrix(X_test, mode='binary')   #  recc to set mode=\"binary\"{yes/no} or \"freq\"{tfidf}\n",
    "        \n",
    "        Xtrain = []\n",
    "        for line in X_train:\n",
    "            # Converting the lines into matrix, line-by-line.\n",
    "            m = tokenizer.texts_to_matrix([line], mode='binary')[0]\n",
    "            Xtrain.append(m)\n",
    "        \n",
    "        Xtest = []\n",
    "        for line in X_test:\n",
    "            # Converting the lines into matrix, line-by-line.\n",
    "            m = tokenizer.texts_to_matrix([line], mode='binary')[0]\n",
    "            Xtest.append(m)\n",
    "        \n",
    "        \n",
    "        n_words = Xtest.shape[1]\n",
    "        \n",
    "        # define network\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, input_shape=(n_words,), activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compile network\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        # fit network\n",
    "        model.fit(Xtrain, ytrain, epochs=nb_epoch, verbose=2)\n",
    "        # evaluate\n",
    "        loss, acc = model.evaluate(Xtest, y_test, verbose=0)\n",
    "        print(\"loss: {}, acc: {}\".format(loss, acc))\n",
    "        result[\"network\"] = acc\n",
    "        \n",
    "        if save:\n",
    "            dump(model, \"saved_runs/network_calibrated.joblib\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc0e44",
   "metadata": {},
   "source": [
    "## Additional features to be created for the final project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1899f12",
   "metadata": {},
   "source": [
    "#### Image to text - recognize samples so we can later use our model to evaluate them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb771137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from \"http://digitalnativestudios.com/textmeshpro/docs/rich-text/\"\n",
    "source_path = r\"materials\\images\\in\\image_text_sample.png\"\n",
    "\n",
    "image = cv2.imread(source_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Remove some noises, this should be later changed to be dynamic \n",
    "gray = cv2.medianBlur(gray, 3)\n",
    "\n",
    "source_path_out = \"\\\\\".join(source_path.split(\"\\\\\")[0:-2])\n",
    "filename = source_path_out + \"\\\\out\\\\\" + \"image_out.png\"\n",
    "cv2.imwrite(filename, gray)\n",
    "\n",
    "# The line below runs pytesseract, changing the stdout to text file that can be later loaded to the code above \n",
    "# text = pytesseract.image_to_string(Image.open(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3dbc1",
   "metadata": {},
   "source": [
    "[Google OCR](https://github.com/tesseract-ocr/tesseract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d9f46",
   "metadata": {},
   "source": [
    "### Voice to text - recognize samples so we can later use our model to evaluate them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc13d4",
   "metadata": {},
   "source": [
    "###### Under development "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f578ddb2",
   "metadata": {},
   "source": [
    "###### Found a cool open-source library to help split the audio into freq bins (fft) and a dataset that helps analyze feelings according the the sound (frequences, rate of change and etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dcb0ae",
   "metadata": {},
   "source": [
    "[librosa - OpenSource](https://librosa.org/doc/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaaff4c",
   "metadata": {},
   "source": [
    "[Data set](\"https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0347a55",
   "metadata": {},
   "source": [
    "# To do list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90116fae",
   "metadata": {},
   "source": [
    "1. Add Bert and ELMO\n",
    "2. Finialize the features\n",
    "3. Clean the data better (preprocessing for the data)\n",
    "4. Make a conclusion and \"in a nutshell segments\" \n",
    "5. Finilze notebook look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d7025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
